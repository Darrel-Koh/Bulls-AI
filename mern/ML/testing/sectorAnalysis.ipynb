{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Analysis of SGX Stock Market\n",
    "\n",
    "##### Steps\n",
    "1. Importing the libraries\n",
    "2. Importing the dataset\n",
    "    - `/Volumes/T7 Touch/Study/SIM/FYP/Data/Complete-List-of-Listed-Companies-on-Singapore-Stock-Exchange-052923.csv`\n",
    "3. Exploratory Data Analysis\n",
    "4. Data Preprocessing\n",
    "    - Seperate the Data into different sectors\n",
    "    - Within each Sector, seperate the data into training and test set\n",
    "5. Building the Model\n",
    "    - Try different models\n",
    "        - Linear Regression\n",
    "        - Random Forest Regression\n",
    "        - Decision Tree Regression\n",
    "        - Support Vector Regression\n",
    "6. Evaluating the Model\n",
    "7. Predicting the Model\n",
    "   - Predicting the stock price of the next day\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import requests\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "# Read in the data from the txt file\n",
    "# path = \"/Volumes/T7 Touch/Study/SIM/FYP/Data/Complete-List-of-Listed-Companies-on-Singapore-Stock-Exchange-052923.csv\"\n",
    "path = \"../../../Data/Complete-List-of-Listed-Companies-on-Singapore-Stock-Exchange-052923.csv\"\n",
    "\n",
    "# Read the data into a DataFrame\n",
    "SGXdf = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the data \n",
    "SGXdf.head()\n",
    "\n",
    "SGXdf.info()\n",
    "\n",
    "SGXdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique sectors\n",
    "sectors = SGXdf['Sector'].unique()\n",
    "\n",
    "# Create a dictionary to store the data for each sector\n",
    "sector_data = {}\n",
    "\n",
    "for sector in sectors:\n",
    "    print(f\"Processing sector {sector}\")\n",
    "    \n",
    "    df_sector = SGXdf[SGXdf['Sector'] == sector]\n",
    "    \n",
    "    # Store the sector data in the dictionary\n",
    "    sector_data[sector] = df_sector\n",
    "\n",
    "# Now sector_data is a dictionary where the keys are sectors and the values are DataFrames with the data for each sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first 5 rows of the 'Real Estate' sector\n",
    "sector_data['Real Estate'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique sectors\n",
    "sectors = SGXdf['Sector'].unique()\n",
    "sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data from the csv file\n",
    "path = '../../../Data/SGX_data_211223.csv'\n",
    "\n",
    "# Read the data into a DataFrame\n",
    "SGXdf = pd.read_csv(path)\n",
    "SGXdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Assets Sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine data for Real Estate and Industrial & Commercial Services sectors\n",
    "RealAssetsSectors = ['Real Estate', 'Industrial & Commercial Services']\n",
    "RealAssetsDF = SGXdf[SGXdf['Sector'].isin(RealAssetsSectors)]\n",
    "\n",
    "# Verify that the data is correct\n",
    "RealAssetsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RealAssetsDF.info()\n",
    "RealAssetsDF.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop S.No, Trading Name and Sector column\n",
    "RealAssetsDF = SGXdf.drop(['S.No.', 'Trading Name'], axis=1)\n",
    "# RealAssetsDF.head()\n",
    "\n",
    "# add .SI to the stock code\n",
    "RealAssetsDF['Code'] = RealAssetsDF['Code'] + '.SI'\n",
    "RealAssetsDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop S.No, Trading Name and Sector column\n",
    "RealAssetsDF = RealAssetsDF.drop(['S.No.', 'Trading Name', 'Sector'], axis=1)\n",
    "RealAssetsDF.head()\n",
    "\n",
    "# add .SI to the stock code\n",
    "RealAssetsDF['Code'] = RealAssetsDF['Code'] + '.SI'\n",
    "RealAssetsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the yfinance API to get the stock data for the stock codes\n",
    "\n",
    "# Get the stock codes from the 'Code' column of your DataFrame\n",
    "symbols = RealAssetsDF['Code'].tolist()\n",
    "\n",
    "# DataFrame to store all the data\n",
    "RealAssets_data = pd.DataFrame()\n",
    "\n",
    "for symbol in symbols:\n",
    "    print(f\"Getting data for {symbol}\")\n",
    "    data = yf.download(symbol, start='2020-01-01', end='2022-12-31')\n",
    "    data['Symbol'] = symbol  # Add a column for the stock symbol\n",
    "    RealAssets_data = pd.concat([RealAssets_data, data])\n",
    "\n",
    "# Now all_data contains the data for all the stocks\n",
    "\n",
    "# Print the first 5 rows\n",
    "print(RealAssets_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes on 'Symbol' and 'Code'\n",
    "# merged_df = RealAssets_data.merge(RealAssetsDF, left_on='Symbol', right_on='Code', how='left')\n",
    "\n",
    "# Save the data to a csv file\n",
    "# merged_df.to_csv('../../../Data/SGX_data_211223.csv')\n",
    "# merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the data\n",
    "SGXdf.info()\n",
    "SGXdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "SGXdf.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift the 'Close' column to create the target column\n",
    "forecast_out = 30  # Number of days in the future you want to predict\n",
    "RealAssets_data['Target'] = RealAssets_data['Adj Close'].shift(-forecast_out)\n",
    "\n",
    "# Drop the last 'forecast_out' rows where 'Target' is NaN\n",
    "RealAssets_data = RealAssets_data[:-forecast_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_9CI_data = RealAssets_data[RealAssets_data['Symbol'] == '9CI.SI']\n",
    "ticker_9CI_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'Code' column from the RealAssets_data DataFrame\n",
    "RealAssets_data = RealAssets_data.drop('Symbol', axis=1)\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = RealAssets_data.corr().round(2)\n",
    "\n",
    "# Print the correlation values for the 'Target' column\n",
    "print(correlation_matrix['Target'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a threshold for the minimum absolute correlation\n",
    "threshold = 0.2\n",
    "\n",
    "# Find the columns where the absolute correlation with the 'Target' column is less than the threshold\n",
    "low_corr_columns = correlation_matrix[correlation_matrix['Target'].abs() < threshold].index\n",
    "\n",
    "# Drop these columns from the DataFrame\n",
    "RealAssets_data = RealAssets_data.drop(low_corr_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RealAssets_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the split point\n",
    "split_point = int(len(RealAssets_data) * 0.8)\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "train_data = RealAssets_data.iloc[:split_point]\n",
    "test_data = RealAssets_data.iloc[split_point:]\n",
    "\n",
    "# Convert the index to datetime\n",
    "train_data.index = pd.to_datetime(train_data.index)\n",
    "test_data.index = pd.to_datetime(test_data.index)\n",
    "\n",
    "# Create new features based on the index\n",
    "train_data.loc[:, 'Year'] = train_data.index.year\n",
    "train_data.loc[:, 'Month'] = train_data.index.month\n",
    "train_data.loc[:, 'Day'] = train_data.index.day\n",
    "\n",
    "test_data.loc[:, 'Year'] = test_data.index.year\n",
    "test_data.loc[:, 'Month'] = test_data.index.month\n",
    "test_data.loc[:, 'Day'] = test_data.index.day\n",
    "\n",
    "# Scale the features between 0 and 1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "test_data = scaler.transform(test_data)\n",
    "\n",
    "# Reshape the data to be 3D\n",
    "train_data = train_data.reshape((train_data.shape[0], 1, train_data.shape[1]))\n",
    "test_data = test_data.reshape((test_data.shape[0], 1, test_data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the train_data\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target\n",
    "X_train = train_data[:, :, :-1]\n",
    "y_train = train_data[:, :, -1]\n",
    "\n",
    "X_test = test_data[:, :, :-1]\n",
    "y_test = test_data[:, :, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the data is correct\n",
    "X_train\n",
    "print(X_train.dtype)\n",
    "print(y_train.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU not available, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, RNN, LSTMCell\n",
    "\n",
    "# Build the LSTM model\n",
    "with tf.device('/GPU:0'):  # replace with '/CPU:0' to force use of CPU\n",
    "    model = Sequential()\n",
    "    model.add(RNN(LSTMCell(50), return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(RNN(LSTMCell(50), return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build the LSTM model\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "# # Build the LSTM model\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(50, return_sequences=False))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(25))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train, y_train, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f'MSE: {mse}, MAE: {mae}, RMSE: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(y_test, label='Actual')\n",
    "plt.plot(y_pred, label='Predicted')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

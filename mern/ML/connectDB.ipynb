{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script connects to a MongoDB database, downloads stock data, preprocesses it, and uploads it to the database.\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Read in CSV file 'Complete-List-of-Listed-Companies-on-Singapore-Stock-Exchange-052923.csv' to extract Trading Name and Code columns. These represent the stock symbols we're interested in.\n",
    "2. Append '.SI' to the end of each Code. This is required because the yFinance API uses '.SI' to denote stocks listed on the Singapore Exchange.\n",
    "3. Establish a connection to the MongoDB database using the connection string from 'config.env'.\n",
    "4. Download stock data for each symbol from the yFinance API. If a symbol is delisted or unavailable, it is skipped and a warning message is printed.\n",
    "5. Preprocess the downloaded data by converting it to a time-series format and setting appropriate column names.\n",
    "6. Upload the preprocessed data to the MongoDB database. Each symbol's data is uploaded as a separate document in the 'ticker_data' collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrels/miniforge3/envs/tf_env/lib/python3.8/site-packages/jax/lib/__init__.py:31: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import yfinance as yf\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bson import ObjectId\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, RNN, LSTMCell, LSTM\n",
    "from tensorflow.keras.models import load_model, save_model\n",
    "from tensorflow import function\n",
    "from bson.binary import Binary\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading data to MongoDB\n",
    "\n",
    "#### Steps:\n",
    "1. Establish a connection to the MongoDB database using the connection string from 'config.env'.\n",
    "2. Upload the preprocessed data to the MongoDB database. Each symbol's data is uploaded as a separate document in the 'ticker_data' collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No.</th>\n",
       "      <th>Trading Name</th>\n",
       "      <th>Code</th>\n",
       "      <th>Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3Cnergy</td>\n",
       "      <td>502</td>\n",
       "      <td>Real Estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5E Resources</td>\n",
       "      <td>NLC</td>\n",
       "      <td>Industrial &amp; Commercial Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8Telecom</td>\n",
       "      <td>AZG</td>\n",
       "      <td>Technology Equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9R</td>\n",
       "      <td>1Y1</td>\n",
       "      <td>Industrial Goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ABR</td>\n",
       "      <td>533</td>\n",
       "      <td>Food &amp; Beverages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No.  Trading Name Code                            Sector\n",
       "0      1       3Cnergy  502                       Real Estate\n",
       "1      2  5E Resources  NLC  Industrial & Commercial Services\n",
       "2      3      8Telecom  AZG              Technology Equipment\n",
       "3      4            9R  1Y1                  Industrial Goods\n",
       "4      5           ABR  533                  Food & Beverages"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data from the csv file\n",
    "path = \"../../Data/Complete-List-of-Listed-Companies-on-Singapore-Stock-Exchange-052923.csv\"\n",
    "\n",
    "# Read the data into a DataFrame\n",
    "SGXdf = pd.read_csv(path)\n",
    "SGXdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the .SI to the end of each symbol in the dataframe\n",
    "# symbols = [symbol + '.SI' for symbol in symbols]\n",
    "# symbols\n",
    "\n",
    "# Add the .SI to the end of each symbol in the dataframe\n",
    "SGXdf['Code'] = SGXdf['Code'] + '.SI'\n",
    "SGXdf.head()\n",
    "\n",
    "# Get the unique sectors\n",
    "symbols = SGXdf['Code'].unique()\n",
    "# Convert numpy array to list\n",
    "symbols_list = symbols.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['40F.SI']\n"
     ]
    }
   ],
   "source": [
    "# Define the stock symbols and time range\n",
    "# symbols = ['U96.SI', 'NLC.SI']\n",
    "# symbols_list = ['U96.SI', 'NLC.SI', 'AZG.SI', '533.SI']\n",
    "symbols_list = ['40F.SI']\n",
    "print(symbols_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No.</th>\n",
       "      <th>Trading Name</th>\n",
       "      <th>Code</th>\n",
       "      <th>Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5E Resources</td>\n",
       "      <td>NLC.SI</td>\n",
       "      <td>Industrial &amp; Commercial Services</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No.  Trading Name    Code                            Sector\n",
       "1      2  5E Resources  NLC.SI  Industrial & Commercial Services"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the matching row in SGXdf for the current symbol\n",
    "matched_row = SGXdf[SGXdf['Code'] == 'NLC.SI']\n",
    "\n",
    "matched_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v3/t0psjdhs29g8j3cghfdfjd9w0000gn/T/ipykernel_86091/1764328768.py:16: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
      "  if latest_record.count() > 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "    S.No.     Trading Name    Code             Sector\n",
      "24     25  Alita Resources  40F.SI  Mineral Resources\n"
     ]
    }
   ],
   "source": [
    "# Load the .env file\n",
    "load_dotenv('../server/config.env')\n",
    "\n",
    "# Get the connection string\n",
    "connection_string = os.getenv('ATLAS_URI')\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = pymongo.MongoClient(connection_string)\n",
    "db = client['bullsai']\n",
    "collection = db['ticker_data']\n",
    "\n",
    "# Get the latest end date and transaction count in the collection\n",
    "latest_record = db.ticker_data.find().sort(\"bucket_end_date\", pymongo.DESCENDING).limit(1)\n",
    "\n",
    "# Initialize latest_end_date and latest_transaction_count\n",
    "if latest_record.count() > 0:\n",
    "    latest_end_date = latest_record[0][\"bucket_end_date\"]\n",
    "    latest_transaction_count = latest_record[0][\"transaction_count\"]\n",
    "else:\n",
    "    latest_end_date = \"2000-01-01\"  # If no data is available, use a default start date\n",
    "    latest_transaction_count = 0\n",
    "\n",
    "# Determine start_date and end_date based on the latest end date\n",
    "start_date = '2000-01-01'\n",
    "end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Fetch data from yFinance for the list of symbols\n",
    "for symbol in symbols_list:\n",
    "    try:\n",
    "        # Fetch data from yFinance for the current symbol\n",
    "        data = yf.download(symbol, start=start_date, end=end_date)\n",
    "        \n",
    "        # Check if data is fetched successfully\n",
    "        if not data.empty:\n",
    "            # Reset index to make the Date column accessible\n",
    "            data.reset_index(inplace=True)\n",
    "\n",
    "            # Preprocess the data\n",
    "            data.columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "            data['Date'] = data['Date'].apply(lambda x: datetime.strftime(x, '%Y-%m-%d'))\n",
    "\n",
    "            # Find the matching row in SGXdf for the current symbol\n",
    "            matched_row_sgx = SGXdf[SGXdf['Code'] == symbol]\n",
    "            print(matched_row_sgx)\n",
    "\n",
    "            # Define trading_name and transactions\n",
    "            trading_name = matched_row_sgx['Trading Name'].values[0] if not matched_row_sgx.empty else None\n",
    "            transactions = data.to_dict('records')  # Removed the drop operation\n",
    "\n",
    "            # Check if data is successfully fetched\n",
    "            if not data.empty:\n",
    "                matched_row = db.ticker_data.find_one({\"symbol\": symbol})\n",
    "                if matched_row:\n",
    "                    # Check if the bucket_end_date is up-to-date\n",
    "                    if matched_row['bucket_end_date'] == data['Date'].max():\n",
    "                        print(f\"Skipping update for symbol {symbol}. bucket_end_date is up-to-date.\")\n",
    "                        continue\n",
    "                        \n",
    "                   # Update existing document\n",
    "                    db.ticker_data.update_one(\n",
    "                        {\"symbol\": symbol},\n",
    "                        {\"$set\": {\"transactions\": transactions,\n",
    "                                \"transaction_count\": len(transactions),\n",
    "                                \"bucket_end_date\": end_date,\n",
    "                                \"trading_name\": trading_name}}\n",
    "                    )\n",
    "\n",
    "\n",
    "                else:\n",
    "                    # Insert new document\n",
    "                    db.ticker_data.insert_one({\n",
    "                        \"trading_name\": trading_name,\n",
    "                        \"symbol\": symbol,\n",
    "                        \"transaction_count\": len(data),\n",
    "                        \"bucket_start_date\": data['Date'].min(),\n",
    "                        \"bucket_end_date\": data['Date'].max(),\n",
    "                        \"transactions\": transactions\n",
    "                    })\n",
    "        else:\n",
    "            print(f\"No data fetched for symbol {symbol}. Skipping update.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch data for symbol {symbol}: {e}\")\n",
    "\n",
    "# Close the MongoDB connection\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MongoDB\n",
    "\n",
    "# Create a client\n",
    "# Read the connection string from the config.env file\n",
    "# Load the .env file\n",
    "load_dotenv('../server/config.env')\n",
    "\n",
    "# Get the connection string\n",
    "connection_string = os.getenv('ATLAS_URI')\n",
    "\n",
    "client = pymongo.MongoClient(connection_string)\n",
    "db = client['bullsai']\n",
    "collection = db['ticker_data']\n",
    "\n",
    "# Define the stock symbols and time range\n",
    "symbols = symbols_list\n",
    "start_date = '2000-01-01'\n",
    "end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Download stock data from yFinance\n",
    "data = yf.download(symbols, start=start_date, end=end_date)\n",
    "\n",
    "# Preprocess the data and convert it to a time-series format\n",
    "data = data.stack().reset_index()\n",
    "data.columns = ['Date', 'Symbol', 'Value']\n",
    "data['Date'] = data['Date'].apply(lambda x: datetime.strftime(x, '%Y-%m-%d'))\n",
    "\n",
    "\n",
    "# Group the data by symbol and create a document for each symbol\n",
    "for symbol in symbols:\n",
    "    # Filter data for the current symbol\n",
    "    symbol_data = data[data['Symbol'] == symbol]\n",
    "    print(symbol_data)\n",
    "    \n",
    "    # Check if the data for the symbol is empty\n",
    "    if symbol_data.empty:\n",
    "        print(f\"Warning: No data found for symbol {symbol}. It might be delisted.\")\n",
    "        continue\n",
    "\n",
    "    # Find the matching row in SGXdf for the current symbol\n",
    "    matched_row = SGXdf[SGXdf['Code'] == symbol]\n",
    "\n",
    "    if not matched_row.empty:\n",
    "        trading_name = matched_row['Trading Name'].values[0]\n",
    "        transactions = symbol_data.drop(columns=['Symbol']).to_dict('records')\n",
    "\n",
    "        document = {\n",
    "            \"_id\": ObjectId(),\n",
    "            \"trading_name\": trading_name,\n",
    "            \"symbol\": symbol,\n",
    "            \"transaction_count\": len(transactions),\n",
    "            \"bucket_start_date\": symbol_data['Date'].min(),\n",
    "            \"bucket_end_date\": symbol_data['Date'].max(),\n",
    "            \"transactions\": transactions\n",
    "        }\n",
    "\n",
    "        # Upload the document to MongoDB\n",
    "        collection.insert_one(document)\n",
    "    else:\n",
    "        print(f\"Warning: No details found for symbol {symbol}\")\n",
    "\n",
    "\n",
    "# Close the MongoDB connection\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MongoDB\n",
    "\n",
    "# Create a client\n",
    "# Read the connection string from the config.env file\n",
    "with open('../server/config.env', 'r') as file:\n",
    "    connection_string = file.read().strip()\n",
    "\n",
    "connection_string = connection_string.replace('ATLAS_URI=', '')\n",
    "\n",
    "client = pymongo.MongoClient(connection_string)\n",
    "db = client['bullsai']\n",
    "collection = db['ticker_data']\n",
    "\n",
    "# Define the stock symbols and time range\n",
    "symbols = symbols_list\n",
    "start_date = '2000-01-01'\n",
    "end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Download stock data from yFinance\n",
    "data = yf.download(symbols, start=start_date, end=end_date)\n",
    "\n",
    "# Preprocess the data and convert it to a time-series format\n",
    "data = data.stack().reset_index()\n",
    "data.columns = ['Date', 'Symbol', 'Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
    "data['Date'] = data['Date'].apply(lambda x: datetime.strftime(x, '%Y-%m-%d'))\n",
    "\n",
    "# Group the data by symbol and create a document for each symbol\n",
    "for symbol in symbols:\n",
    "    # Filter data for the current symbol\n",
    "    symbol_data = data[data['Symbol'] == symbol]\n",
    "    \n",
    "    # Check if the data for the symbol is empty\n",
    "    if symbol_data.empty:\n",
    "        print(f\"Warning: No data found for symbol {symbol}. It might be delisted.\")\n",
    "        continue\n",
    "\n",
    "    # Find the matching row in SGXdf for the current symbol\n",
    "    matched_row = SGXdf[SGXdf['Code'] == symbol]\n",
    "\n",
    "    if not matched_row.empty:\n",
    "        trading_name = matched_row['Trading Name'].values[0]\n",
    "        transactions = symbol_data.drop(columns=['Symbol']).to_dict('records')\n",
    "\n",
    "        document = {\n",
    "            \"_id\": ObjectId(),\n",
    "            \"trading_name\": trading_name,\n",
    "            \"symbol\": symbol,\n",
    "            \"transaction_count\": len(transactions),\n",
    "            \"bucket_start_date\": symbol_data['Date'].min(),\n",
    "            \"bucket_end_date\": symbol_data['Date'].max(),\n",
    "            \"transactions\": transactions\n",
    "        }\n",
    "\n",
    "        # Upload the document to MongoDB\n",
    "        collection.insert_one(document)\n",
    "    else:\n",
    "        print(f\"Warning: No details found for symbol {symbol}\")\n",
    "\n",
    "\n",
    "# Close the MongoDB connection\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download values from MongoDB\n",
    "Steps:\n",
    "1. Connect to MongoDB\n",
    "2. Query the data\n",
    "3. Convert the data to a DataFrame\n",
    "4. Close the MongoDB connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare Symbol to be used for testing\n",
    "symbol = 'D05.SI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MongoDB\n",
    "with open('../server/config.env', 'r') as file:\n",
    "    connection_string = file.read().strip()\n",
    "\n",
    "connection_string = connection_string.replace('ATLAS_URI=', '')\n",
    "\n",
    "client = pymongo.MongoClient(connection_string)\n",
    "db = client['bullsai']\n",
    "collection = db['ticker_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the data from MongoDB\n",
    "dataTest = collection.find_one({\"symbol\": symbol})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "\n",
    "The downloaded data is in a format that is not suitable for analysis. It is converted to a time-series format and the column names are set appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to a DataFrame\n",
    "dataDF = pd.DataFrame(dataTest['transactions'])\n",
    "dataDFTest = dataDF.set_index('Date')\n",
    "dataDFTest.head()\n",
    "# dataDFTest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure your index is a DateTimeIndex\n",
    "dataDFTest.index = pd.to_datetime(dataDFTest.index)\n",
    "\n",
    "# Resample to weekly frequency, taking the last price each week\n",
    "weekly_data = dataDFTest['Adj Close'].resample('W').last()\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title('Adj Close Price History')\n",
    "plt.plot(weekly_data)\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Adj Price SGD ($)', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_db():\n",
    "    with open('../server/config.env', 'r') as file:\n",
    "        connection_string = file.read().strip()\n",
    "\n",
    "    connection_string = connection_string.replace('ATLAS_URI=', '')\n",
    "\n",
    "    client = pymongo.MongoClient(connection_string)\n",
    "    db = client['bullsai']\n",
    "    return db\n",
    "\n",
    "def download_data(symbol):\n",
    "    db = connect_to_db()\n",
    "    collection = db['ticker_data']\n",
    "    data = collection.find_one({\"symbol\": symbol})\n",
    "\n",
    "    # if data is not None and 'transactions' in data:\n",
    "    #     df = pd.DataFrame(data['transactions'])\n",
    "    #     df = df.set_index('Date')\n",
    "    # else:\n",
    "    #     print(f\"No data found for symbol {symbol}\")\n",
    "    #     df = pd.DataFrame()\n",
    "\n",
    "    if data is not None and 'transactions' in data:\n",
    "        # Convert the data to a DataFrame\n",
    "        dataDF = pd.DataFrame(data['transactions'])\n",
    "        dataDF = dataDF.set_index('Date')\n",
    "\n",
    "    return dataDF\n",
    "\n",
    "def create_dataset(data):\n",
    "    data = data.filter(['Adj Close'])\n",
    "    dataset = data.values\n",
    "    training_data_len = int(np.ceil( len(dataset) * .95 ))\n",
    "    return dataset, training_data_len\n",
    "\n",
    "def scale_data(dataset):\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    return scaler.fit_transform(dataset), scaler\n",
    "\n",
    "def create_training_data(scaled_data, training_data_len):\n",
    "    train_data = scaled_data[0:int(training_data_len), :]\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i in range(60, len(train_data)):\n",
    "        x_train.append(train_data[i-60:i, 0])\n",
    "        y_train.append(train_data[i, 0])\n",
    "    return np.array(x_train), np.array(y_train)\n",
    "\n",
    "def reshape_data(x_train):\n",
    "    return np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "\n",
    "def build_and_train_model(x_train, y_train):\n",
    "    model = Sequential()\n",
    "    model.add(RNN(LSTMCell(128), return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "    model.add(RNN(LSTMCell(64), return_sequences=False))\n",
    "    # model.add(LSTM(128, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "    # model.add(LSTM(64, return_sequences=False))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(x_train, y_train, batch_size=1, epochs=2)\n",
    "    return model\n",
    "\n",
    "def create_test_data(scaled_data, dataset, training_data_len):\n",
    "    test_data = scaled_data[training_data_len - 60: , :]\n",
    "    x_test = []\n",
    "    y_test = dataset[training_data_len:, :]\n",
    "    for i in range(60, len(test_data)):\n",
    "        x_test.append(test_data[i-60:i, 0])\n",
    "    return np.array(x_test), y_test\n",
    "\n",
    "def make_predictions(model, x_test, scaler):\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))\n",
    "    predictions = model.predict(x_test)\n",
    "    return scaler.inverse_transform(predictions)\n",
    "\n",
    "def calculate_rmse(predictions, y_test):\n",
    "    return np.sqrt(np.mean(((predictions - y_test) ** 2)))\n",
    "\n",
    "def plot_data(data, training_data_len, predictions, symbol):\n",
    "    train = data[:training_data_len]\n",
    "    valid = data[training_data_len:].copy()\n",
    "    valid.loc[:, 'Predictions'] = predictions\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.title(symbol + ' Model')\n",
    "    plt.xlabel('Date', fontsize=18)\n",
    "    plt.ylabel('Adj Close Price SGD ($)', fontsize=18)\n",
    "    plt.plot(train['Adj Close'])\n",
    "    plt.plot(valid[['Adj Close', 'Predictions']])\n",
    "    plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "def save_model(model, model_path):\n",
    "    model.save(model_path)\n",
    "\n",
    "def load_model_if_exists(model_path):\n",
    "    if os.path.exists(model_path):\n",
    "        return load_model(model_path)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def load_model_from_db(symbol):\n",
    "    # Connect to MongoDB\n",
    "    db = connect_to_db()\n",
    "    collection = db['ticker_data']\n",
    "    doc = collection.find_one({'symbol': symbol})\n",
    "\n",
    "    if doc is not None:\n",
    "        print(f\"Document found for symbol {symbol}\")\n",
    "        if 'model' in doc:\n",
    "            print(\"Model key found in document\")\n",
    "            binary_model = doc['model']\n",
    "            # Write the binary model to a file\n",
    "            with open('model.h5', 'wb') as f:\n",
    "                f.write(binary_model)\n",
    "            # Load the model from the file\n",
    "            model = load_model('model.h5')\n",
    "        else:\n",
    "            print(\"Model key not found in document\")\n",
    "            model = None\n",
    "    else:\n",
    "        print(f\"No document found for symbol {symbol}\")\n",
    "        model = None\n",
    "\n",
    "    return model\n",
    "\n",
    "def save_model_to_db(model, symbol):\n",
    "    # Save the model to a file\n",
    "    model.save('model.h5')\n",
    "\n",
    "    # Read the model file and convert it to binary\n",
    "    with open('model.h5', 'rb') as f:\n",
    "        binary_model = Binary(pickle.dumps(f.read()))\n",
    "\n",
    "    # Connect to MongoDB\n",
    "    db = connect_to_db()\n",
    "    collection = db['models']\n",
    "\n",
    "    # Store the binary model in MongoDB\n",
    "    collection.insert_one({'symbol': symbol, 'model': binary_model})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"D05.SI\"\n",
    "data = download_data(symbol)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    symbol = \"U11.SI\"\n",
    "    model_path = f\"models/{symbol}_model.h5\"\n",
    "    \n",
    "    # Use the new download_data function\n",
    "    data = download_data(symbol)\n",
    "    dataset, training_data_len = create_dataset(data)\n",
    "    scaled_data, scaler = scale_data(dataset)\n",
    "    \n",
    "    # Use the new load_model_from_db function\n",
    "    model = load_model_from_db(symbol)\n",
    "\n",
    "    if model is None:\n",
    "        print(f\"No model found for symbol {symbol}. Please train a model first.\")\n",
    "\n",
    "        # Create the training data\n",
    "        x_train, y_train = create_training_data(scaled_data, training_data_len, portion=0.1)\n",
    "        x_train = reshape_data(x_train)\n",
    "\n",
    "        # Build and train the model\n",
    "        model = build_and_train_model(x_train, y_train)\n",
    "\n",
    "        # Save the model to MongoDB\n",
    "        save_model_to_db(model, symbol)\n",
    "    else:\n",
    "        print(f\"Model found for symbol {symbol}. Using existing model.\")\n",
    "        return\n",
    "\n",
    "    x_test, y_test = create_test_data(scaled_data, dataset, training_data_len)\n",
    "    predictions = make_predictions(model, x_test, scaler)\n",
    "    plot_data(data, training_data_len, predictions, symbol)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfdml_plugin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
